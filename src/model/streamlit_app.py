import logging
import streamlit as st
import llm_model
import html_scrapping
import lead_dataset_creation
from Config.param import TIME_WINDOW

# Configuration de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration de la page Streamlit
st.set_page_config(page_title="Lead Generation")

# Fonction pour gÃ©nÃ©rer des leads basÃ© sur l'URL entrÃ©e par l'utilisateur
def generate_leads(user_input: str) -> None:
    """
    Generate leads based on the user input URL and display on the Streamlit app.

    Args:
        user_input (str): The URL provided by the user.
    """
    logger.info("Starting scrapping text data...")
    html_raw_code = html_scrapping.extract_readable_text(user_input)
    logger.info("Scrapping is done")
    logger.info("GPT 3.5 is processing...")

    df = llm_model.create_table_with_job(user_input, html_raw_code)
    dfConverter = lead_dataset_creation.LeadDataFrameConverter(df)
    df_lead = dfConverter.convert_to_lead_dataframe(TIME_WINDOW)

    df_lead.to_csv("output_example.csv")
    st.table(df_lead)

def main() -> None:
    """
    Main function to handle the Streamlit app interface and interactions.
    """
    # Sidebar contents
    with st.sidebar:
        st.title("ğŸ’¬ Lead Generation")
        st.markdown(
            """
            ## About    
            ğŸ’¡ List of leads generated by Algorithm Dimension for Kara
            """
        )

    user_input = st.text_input("Enter the url of the job postings page:")

    if user_input:
        st.write(f"Searching for customers of {user_input}...")
        generate_leads(user_input)

if __name__ == '__main__':
    main()
